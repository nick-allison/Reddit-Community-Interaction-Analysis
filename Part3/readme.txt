I decided to move away from calculating Page Rank values, and go in a different direciton for this part of the project.  I was interested to learn to what extent a high page rank correlates to high centrality values for this data set.

The clean data file that I generated in part 1 of the project would work just as well for this part.  I copied the data file over, and wrote some Python code to use Networkx to calculate the degree, betweenness, and closeness centralities for each of the nodes.

I was spoiled by parts 1 and 2 of the project going so smoothly, and so I was not expecting any problems here.  My computer, however, was not able to calculate any of these values even after running the Python program for more than a day.  My computer has a modern i7 and 16GB of RAM, so I think this speaks to just how difficult and computing intensive it would be to calculate these metrics.

After around 36 hours of the program running, I gave up and killed it.  This part of the project was unsuccessful.